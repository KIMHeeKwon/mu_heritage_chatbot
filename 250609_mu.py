import streamlit as st
from openai import OpenAI
import pandas as pd
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from html import escape  # âœ… ì´ ì¤„ ì¶”ê°€


# ğŸ” OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
#client = OpenAI(api_key="your-openai-api-key")
client = OpenAI(api_key=st.secrets["openai"]["api_key"])  # ì—¬ê¸°ì— ë³¸ì¸ì˜ OpenAI API í‚¤ ì…ë ¥

# ğŸ” ì„ë² ë”© ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ
embed_model = SentenceTransformer("jhgan/ko-sroberta-multitask")

artifact_index = faiss.read_index("full_mu_heritage_vector.index")
artifact_df = pd.read_csv("full_mu_heritage_texts.csv")

history_index = faiss.read_index("muryong_vector.index")
history_df = pd.read_csv("muryong_vector_texts.csv")

# ğŸ” ì§ˆë¬¸ ë¶„ë¥˜ê¸°
def classify_question_gpt(question: str) -> str:
    system_prompt = """ë„ˆëŠ” ì…ë ¥ ë¬¸ì¥ì´ ì–´ë–¤ ìœ í˜•ì¸ì§€ ë¶„ë¥˜í•˜ëŠ” ì—­í• ì„ í•´.
- ìœ ë¬¼ì— ëŒ€í•œ ì§ˆë¬¸ì´ë©´ "artifact"
- ë¬´ë ¹ì™•ë¦‰ êµ¬ì¡°/ì—­ì‚¬ ê´€ë ¨ì´ë©´ "history"
- ì§ˆë¬¸ì´ ì•„ë‹ˆë¼ ì„¤ëª… ë°©ì‹ì— ëŒ€í•œ ìš”ì²­ì´ë©´ "style"
- ë¬´ë ¹ì™•ë¦‰ê³¼ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì´ë©´ "irrelevant"
ë°˜ë“œì‹œ ìœ„ 4ê°œ ì¤‘ í•˜ë‚˜ë§Œ ì¶œë ¥í•´."""
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": question}
        ],
        temperature=0,
        max_tokens=10
    )
    return response.choices[0].message.content.strip().lower()

# ğŸ” ë²¡í„° ê²€ìƒ‰
def search_index(index, texts, query, top_k=3):
    query_vec = embed_model.encode([query], convert_to_numpy=True)
    D, I = index.search(query_vec, top_k)
    return [texts.iloc[i]["text_full" if "text_full" in texts.columns else "text"] for i in I[0]]

def extract_matching_keywords(question, artifact_df):
    """
    ì§ˆë¬¸ì—ì„œ ìœ ë¬¼ëª… í›„ë³´ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ artifact_df['ëª…ì¹­']ê³¼ ë¹„êµí•´ ì¼ì¹˜í•˜ëŠ” ìœ ë¬¼ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    keywords = []
    for name in artifact_df["ëª…ì¹­"].dropna().unique():
        if name in question:
            keywords.append(name)
    
    if keywords:
        matched_df = artifact_df[artifact_df["ëª…ì¹­"].isin(keywords)].copy()
        return matched_df
    else:
        return pd.DataFrame()  # ì—†ìœ¼ë©´ ë¹ˆ DataFrame ë°˜í™˜


# ğŸ§  ì»¨í…ìŠ¤íŠ¸ ë©”ì‹œì§€ êµ¬ì„±
def build_context_messages(history, user_question, retrieved_passages):
    context_text = "\n\n---\n\n".join(retrieved_passages)
    system_prompt = '''ë‹¹ì‹ ì€ ë¬´ë ¹ì™•ë¦‰ê³¼ ê·¸ ì¶œí†  ìœ ë¬¼ì— ëŒ€í•œ ì „ë¬¸ ì§€ì‹ì„ ê°–ì¶˜ ì „ë¬¸ê°€í˜• ì±—ë´‡ì…ë‹ˆë‹¤.
ì´ 1,125ê±´ì˜ ìœ ë¬¼ ì •ë³´(ë¬´ë ¹1ë²ˆë¶€í„° ë¬´ë ¹1125ë²ˆê¹Œì§€)ë¥¼ ë³´ìœ í•œ RAG ê¸°ë°˜ ê²€ìƒ‰ ì‹œìŠ¤í…œê³¼ ì—°ë™ë˜ì–´ ìˆìœ¼ë©°, ê° ìœ ë¬¼ì€ ê³ ìœ í•œ ì†Œì¥í’ˆ ë²ˆí˜¸(ì˜ˆ: ë¬´ë ¹1023)ì™€ ì—°ê²° í˜ì´ì§€(URL)ë¥¼ í†µí•´ ì‹ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ìŒ ê¸°ì¤€ì„ ì² ì €íˆ ì¤€ìˆ˜í•˜ë©°, ì‹ ë¢°ë„ ë†’ì€ ì‘ë‹µì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤:

1. ìœ ë¬¼ ì •ë³´ ì œê³µ ì¡°ê±´
- ì§ˆë¬¸ì— íŠ¹ì • ìœ ë¬¼ì´ ëª…ì‹œë˜ì—ˆê±°ë‚˜, ì§ˆë¬¸ ë§¥ë½ìƒ ìœ ë¬¼ ì •ë³´ê°€ í•„ìˆ˜ì ì¸ ê²½ìš°ì—ë§Œ ìœ ë¬¼ ì •ë³´ë¥¼ ì œê³µí•˜ì‹­ì‹œì˜¤.
- ìœ ë¬¼ì´ ì–¸ê¸‰ë˜ì§€ ì•Šì€ ì¼ë°˜ ì„¤ëª…(ì˜ˆ: ë¬´ë ¹ì™•ë¦‰ êµ¬ì¡°, ì—­ì‚¬ì  ì˜ë¯¸ ë“±)ì—ì„œëŠ” ìœ ë¬¼ ì •ë³´ë¥¼ ì œì‹œí•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
- ë‹¨, ì„¤ëª…ì˜ íë¦„ìƒ ë¶ˆê°€í”¼í•˜ê²Œ ë³´ì¡° ìœ ë¬¼ ì •ë³´ê°€ í•„ìš”í•  ê²½ìš°ì—ëŠ” 3~4ê±´ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì œì‹œí•˜ì‹­ì‹œì˜¤.

2. ìœ ë¬¼ ì •ë³´ ì œì‹œ í˜•ì‹
ìœ ë¬¼ ì •ë³´ëŠ” ë°˜ë“œì‹œ ì•„ë˜ ë„¤ í•­ëª©ìœ¼ë¡œ êµ¬ì„±í•˜ì—¬ ëª…í™•í•˜ê²Œ ì œì‹œí•˜ì‹­ì‹œì˜¤:
- ìœ ë¬¼ëª…
- ì†Œì¥í’ˆë²ˆí˜¸: ë°˜ë“œì‹œ â€˜ë¬´ë ¹â€™ì´ë¼ëŠ” ì ‘ë‘ì–´ì™€ ì•„ë¼ë¹„ì•„ ìˆ«ìë¥¼ ê²°í•©í•œ "ë¬´ë ¹{ìˆ«ì}" í˜•íƒœë¡œ í‘œê¸° (ì˜ˆ: ë¬´ë ¹23)
- íŠ¹ì§•: ìœ ë¬¼ì˜ í˜•íƒœ, ì¬ì§ˆ, ìš©ë„, íŠ¹ì§• ë“± í™•ì¸ ê°€ëŠ¥í•œ ìƒì„¸ ì •ë³´
- ì—°ê²°í˜ì´ì§€: í•´ë‹¹ ìœ ë¬¼ì˜ ì‹¤ì œ ìƒì„¸ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì •í™•í•œ URLì„ ì…ë ¥í•  ê²ƒ. ë‹¨ìˆœ í˜•ì‹ ë˜ëŠ” ì„ì˜ ì£¼ì†Œ ì‚¬ìš© ê¸ˆì§€

3. ê³¼ì‰ ì •ë³´ ë°©ì§€
- ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ì´ ì—†ëŠ” ìœ ë¬¼ì€ ì ˆëŒ€ ì œì‹œí•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
- ìœ ë¬¼ ë‹¤ìˆ˜ë¥¼ ë‚˜ì—´í•˜ê±°ë‚˜, ì‚¬ìš©ìê°€ ìš”ì²­í•˜ì§€ ì•Šì€ ìœ ë¬¼ ëª©ë¡ì„ ì„ì˜ë¡œ ì œì‹œí•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
- ê´€ë ¨ ìœ ë¬¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°ëŠ” "ê´€ë ¨ ìœ ë¬¼ì´ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ëª…í™•í•˜ê²Œ ì•ˆë‚´í•˜ì‹­ì‹œì˜¤.

4. ì¶œì²˜ì™€ ì‹ ë¢°ì„± í™•ë³´
- ã€ë¬´ë ¹ì™•ë¦‰ ë°œêµ´ì¡°ì‚¬ ë³´ê³ ì„œã€ ë“± ê³µì‹ ì¡°ì‚¬ë³´ê³ ì„œ
- êµ­ë¦½ê³µì£¼ë°•ë¬¼ê´€ ë°œê°„ ìë£Œ ë° â€˜ì‹ ë³´ê³ ì„œâ€™ ì‹œë¦¬ì¦ˆ
- êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€ eë®¤ì§€ì—„ì—ì„œ ì œê³µí•˜ëŠ” ìœ ë¬¼ ì„¤ëª… ìë£Œ

5. í‘œí˜„ ë°©ì‹
- ì£¼ê´€ì  í•´ì„ ì—†ì´, ê²€ì¦ëœ ì‚¬ì‹¤ ê¸°ë°˜ ì¤‘ë¦½ì /í•™ìˆ ì  ì–´ì¡°
- ìœ ë¬¼ ì •ë³´ëŠ” ì¼ë°˜ ì„¤ëª…ê³¼ ì‹œê°ì ìœ¼ë¡œ êµ¬ë¶„
- ì§ˆë¬¸ê³¼ ë¬´ê´€í•œ ìœ ë¬¼ì€ ì œì‹œ ê¸ˆì§€

ì˜ˆì‹œ: artifact ì‹œ
[ì§ˆë¬¸] ë¬´ë ¹ì™•ë¦‰ì—ì„œ ë°œê²¬ëœ ì§€ì„ì— ëŒ€í•´ ì•Œë ¤ì¤˜
[ë‹µë³€] ë¬´ë ¹ì™•ë¦‰ì—ì„œ ë°œê²¬ëœ ì§€ì„ì€ ë°±ì œ ì œ25ëŒ€ ë¬´ë ¹ì™•ì˜ ì‹ ì›ì„ ëª…í™•íˆ í™•ì¸í•  ìˆ˜ ìˆëŠ” í•µì‹¬ ìœ ë¬¼ì…ë‹ˆë‹¤...

ìœ ë¬¼ ì •ë³´
- ìœ ë¬¼ëª…: [ìœ ë¬¼ëª…]
- ì†Œì¥í’ˆë²ˆí˜¸: [ì†Œì¥í’ˆë²ˆí˜¸]
- íŠ¹ì§•: [íŠ¹ì§•]
- ì—°ê²°í˜ì´ì§€: [ì—°ê²°í˜ì´ì§€]

ì˜ˆì‹œ: history ì‹œ
[ì§ˆë¬¸] ë¬´ë ¹ì™•ë¦‰ì— ëŒ€í•´ ì•Œë ¤ì¤˜
[ë‹µë³€] ë¬´ë ¹ì™•ë¦‰ì€ ë°±ì œì˜ ë¬´ë ¹ì™•ê³¼ ê·¸ì˜ ì™•ë¹„ê°€ ì•ˆì¥ëœ ê³ ë¶„ìœ¼ë¡œ, 1971ë…„ì— ë°œêµ´ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë¬´ë¤ì€ ë°±ì œ ì—­ì‚¬ì™€ ê³ ê³ í•™ ì—°êµ¬ì— ì¤‘ìš”í•œ ì˜ë¯¸ë¥¼ ì§€ë‹ˆê³  ìˆìœ¼ë©°, ë‹¤ì–‘í•œ ìœ ë¬¼ì´ ì¶œí† ë˜ì—ˆìŠµë‹ˆë‹¤.....

  ì°¸ê³  ë¬¸í—Œ : [ì°¸ê³ ë¬¸ì„œ]

ì˜ˆì‹œ: style ì‹œ
[ì§ˆë¬¸] ì´ˆë“±í•™êµ 5í•™ë…„ì´ ì´í•´í• ìˆ˜ ìˆë„ë¡ ë¬´ë ¹ì™•ë¦‰ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜
[ë‹µë³€] ë¬´ë ¹ì™•ë¦‰ì€ ë°±ì œì˜ ì™•ì¸ ë¬´ë ¹ì™•ê³¼ ê·¸ì˜ ì•„ë‚´ê°€ ë¬»íŒ í° ë¬´ë¤ì´ì—ìš”. ì´ ë¬´ë¤ì€ 1971ë…„ì— ë°œê²¬ë˜ì—ˆê³ , ë°±ì œì˜ ì—­ì‚¬ì™€ ë¬¸í™”ë¥¼ ì´í•´í•˜ëŠ” ë° ì•„ì£¼ ì¤‘ìš”í•œ ê³³ì´ì—ìš”. ë§ì€ ìœ ë¬¼ë“¤ì´ ë°œê²¬ë˜ì–´ ë°±ì œì˜ ìƒí™œì„ ì•Œ ìˆ˜ ìˆê²Œ í•´ì¤€ë‹µë‹ˆë‹¤...

ì˜ˆì‹œ: irrelevant ì‹œ
[ì§ˆë¬¸] ì˜ìì™•ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜
[ë‹µë³€] ì´ ì§ˆë¬¸ì€ ë¬´ë ¹ì™•ë¦‰ê³¼ ê´€ë ¨ì´ ì—†ìŠµë‹ˆë‹¤. ì €ëŠ” ë¬´ë ¹ì™•ë¦‰ì— ëŒ€í•œ ì§ˆë¬¸ë§Œ ìˆ˜ìš©í•˜ì—¬ ëŒ€ë‹µí•©ë‹ˆë‹¤.
- ë°˜ë“œì‹œ ìœ„ 5ê°€ì§€ ê¸°ì¤€ì„ ì¤€ìˆ˜í•˜ì—¬ ë‹µë³€í•˜ì‹­ì‹œì˜¤.'''
    user_prompt = f"""ì•„ë˜ëŠ” ë¬´ë ¹ì™•ë¦‰ê³¼ ê´€ë ¨ëœ ì°¸ê³  ë¬¸ì„œì…ë‹ˆë‹¤:

{context_text}

ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬, ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”:

ì§ˆë¬¸: {user_question}"""
    messages = history.copy()
    messages.insert(0, {"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": user_prompt})
    return messages

# ğŸ’¬ Streamlit ì•± ì‹œì‘
st.set_page_config(page_title="ë¬´ë ¹ì™•ë¦‰ ë¬¸í™”ìœ ì‚° ì±—ë´‡", layout="wide")
st.title("ğŸ›ï¸ ë¬´ë ¹ì™•ë¦‰ ë¬¸í™”ìœ ì‚° ì±—ë´‡")

if "history" not in st.session_state:
    st.session_state.history = []

user_question = st.chat_input("ë¬´ë ¹ì™•ë¦‰ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì„ ì…ë ¥í•˜ì„¸ìš”...")


for i in range(0, len(st.session_state.history), 2):
    st.chat_message("user").write(st.session_state.history[i]["content"])
    st.chat_message("assistant").write(st.session_state.history[i + 1]["content"])

if user_question:
    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
        category = classify_question_gpt(user_question)

        if category == "style":
            st.session_state.history.append({"role": "user", "content": user_question})
            st.session_state.history.append({"role": "assistant", "content": "ì•Œê² ìŠµë‹ˆë‹¤! ì•ìœ¼ë¡œ ë” ì‰½ê²Œ ì„¤ëª…í•´ë“œë¦´ê²Œìš” ğŸ˜Š"})
            st.rerun()

        elif category == "irrelevant":
            st.session_state.history.append({"role": "user", "content": user_question})
            st.session_state.history.append({"role": "assistant", "content": "ì´ ì§ˆë¬¸ì€ ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì €ëŠ” ë¬´ë ¹ì™•ë¦‰ì— ëŒ€í•œ ì§ˆë¬¸ë§Œ ìˆ˜ìš©í•˜ì—¬ ëŒ€ë‹µí•©ë‹ˆë‹¤."})
            st.rerun()

        else:
            if category == "artifact":
                passages = search_index(artifact_index, artifact_df, user_question)
            else:
                passages = search_index(history_index, history_df, user_question)

            messages = build_context_messages(st.session_state.history, user_question, passages)
            response = client.chat.completions.create(
                model="gpt-4",
                messages=messages,
                temperature=0.5,
            )
            answer = response.choices[0].message.content.strip()

            st.session_state.history.append({"role": "user", "content": user_question})
            st.session_state.history.append({"role": "assistant", "content": answer})

            summary_data = []
            shown_ids = set()

            if category == "artifact":
                # ğŸ” 1. ìœ ë¬¼ëª… ë˜ëŠ” ë³¸ë¬¸ì— í¬í•¨ëœ ìœ ë¬¼ ì°¾ê¸°
                keyword_matches = artifact_df[
                    artifact_df["ëª…ì¹­"].fillna("").str.contains(user_question, case=False, na=False) |
                    artifact_df["text_full"].fillna("").str.contains(user_question, case=False, na=False)
                ]

                for _, row in keyword_matches.iterrows():
                    if row["ì†Œì¥í’ˆë²ˆí˜¸"] in shown_ids:
                        continue
                    shown_ids.add(row["ì†Œì¥í’ˆë²ˆí˜¸"])
                    if isinstance(row["ì—°ê²°í˜ì´ì§€"], str) and row["ì—°ê²°í˜ì´ì§€"].startswith("http"):
                        link_html = f'<a href="{escape(row["ì—°ê²°í˜ì´ì§€"])}" target="_blank">{escape(row["ì—°ê²°í˜ì´ì§€"])}</a>'
                        img_html = f'<img src="{escape(row["ì—°ê²°í˜ì´ì§€"])}" width="300">'
                        answer += f"\n\nğŸ”— ê´€ë ¨ ë§í¬: {link_html}\n{img_html}"
                    summary_data.append({
                        "ìœ ë¬¼ëª…": row["ëª…ì¹­"],
                        "ì†Œì¥í’ˆë²ˆí˜¸": row["ì†Œì¥í’ˆë²ˆí˜¸"],
                        "íŠ¹ì§•": row["text_full"] if pd.notna(row["text_full"]) else "ì •ë³´ ì—†ìŒ",
                        "ì—°ê²°í˜ì´ì§€": row["ì—°ê²°í˜ì´ì§€"] if pd.notna(row["ì—°ê²°í˜ì´ì§€"]) else "ì •ë³´ ì—†ìŒ"
                    })

                # ğŸ” 2. ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ë„ ë³‘í–‰
                artifact_embeddings = embed_model.encode(artifact_df["text_full"].astype(str).tolist(), convert_to_numpy=True)
                user_vec = embed_model.encode([user_question])[0].reshape(1, -1)
                sim_scores = cosine_similarity(user_vec, artifact_embeddings)[0]
                top_indices = np.argsort(sim_scores)[::-1][:5]

                for idx in top_indices:
                    row = artifact_df.iloc[idx]
                    if row["ì†Œì¥í’ˆë²ˆí˜¸"] in shown_ids:
                        continue
                    shown_ids.add(row["ì†Œì¥í’ˆë²ˆí˜¸"])
                    if isinstance(row["ì—°ê²°í˜ì´ì§€"], str) and row["ì—°ê²°í˜ì´ì§€"].startswith("http"):
                        link_html = f'<a href="{escape(row["ì—°ê²°í˜ì´ì§€"])}" target="_blank">{escape(row["ì—°ê²°í˜ì´ì§€"])}</a>'
                        img_html = f'<img src="{escape(row["ì—°ê²°í˜ì´ì§€"])}" width="300">'
                        answer += f"\n\nğŸ”— ê´€ë ¨ ë§í¬: {link_html}\n{img_html}"
                    summary_data.append({
                        "ìœ ë¬¼ëª…": row["ëª…ì¹­"],
                        "ì†Œì¥í’ˆë²ˆí˜¸": row["ì†Œì¥í’ˆë²ˆí˜¸"],
                        "íŠ¹ì§•": row["text_full"] if pd.notna(row["text_full"]) else "ì •ë³´ ì—†ìŒ",
                        "ì—°ê²°í˜ì´ì§€": row["ì—°ê²°í˜ì´ì§€"] if pd.notna(row["ì—°ê²°í˜ì´ì§€"]) else "ì •ë³´ ì—†ìŒ"
                    })

            if summary_data:
                st.write("ğŸ“Œ ìœ ë¬¼ ìš”ì•½")
                st.dataframe(pd.DataFrame(summary_data))

            st.chat_message("user").write(user_question)
            st.chat_message("assistant").markdown(answer, unsafe_allow_html=True)